{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BuQfFg2vAdYE"
   },
   "source": [
    "# Installs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorboard\n",
    "!pip install open3d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6riTt2NNUSMc"
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lsPkMvcsUmsV"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import open3d as o3d\n",
    "\n",
    "import json\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import pytorch3d\n",
    "except ModuleNotFoundError:\n",
    "    need_pytorch3d=True\n",
    "if need_pytorch3d:\n",
    "    if torch.__version__.startswith(\"1.7\") and sys.platform.startswith(\"linux\"):\n",
    "        # We try to install PyTorch3D via a released wheel.\n",
    "        version_str=\"\".join([\n",
    "            f\"py3{sys.version_info.minor}_cu\",\n",
    "            torch.version.cuda.replace(\".\",\"\"),\n",
    "            f\"_pyt{torch.__version__[0:5:2]}\"\n",
    "        ])\n",
    "        !pip install pytorch3d -f https://dl.fbaipublicfiles.com/pytorch3d/packaging/wheels/{version_str}/download.html\n",
    "    else:\n",
    "        # We try to install PyTorch3D from source.\n",
    "        !curl -LO https://github.com/NVIDIA/cub/archive/1.10.0.tar.gz\n",
    "        !tar xzf 1.10.0.tar.gz\n",
    "        os.environ[\"CUB_HOME\"] = os.getcwd() + \"/cub-1.10.0\"\n",
    "        !pip install 'git+https://github.com/facebookresearch/pytorch3d.git@stable'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NG_k2nw1gcc_"
   },
   "outputs": [],
   "source": [
    "from pytorch3d.transforms import so3_relative_angle, matrix_to_quaternion, quaternion_to_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hD-w8MgYU1wR"
   },
   "source": [
    "# Network Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TG1F7LnAlpPD"
   },
   "source": [
    "## Input Transform Layer\n",
    "\n",
    "This layer corresponds to the input transform layer as described in PointNet architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wI__yrqtlzkv"
   },
   "outputs": [],
   "source": [
    "class TNet3(nn.Module):\n",
    "    '''\n",
    "    T-Net implementation with 3x3 transform as output\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        super(TNet3,self).__init__()\n",
    "        # shared MLP\n",
    "        self.conv1 = nn.Conv1d(3,64,1)\n",
    "        self.conv2 = nn.Conv1d(64,128,1)\n",
    "        self.conv3 = nn.Conv1d(128,1024,1)\n",
    "        # fc layers\n",
    "        self.fc1 = nn.Linear(1024,512)\n",
    "        self.fc2 = nn.Linear(512,256)\n",
    "        # output layer\n",
    "        self.fc3 = nn.Linear(256,9)\n",
    "        # batch norm layers\n",
    "        self.bn1 = nn.BatchNorm1d(64)\n",
    "        self.bn2 = nn.BatchNorm1d(128)\n",
    "        self.bn3 = nn.BatchNorm1d(1024)\n",
    "        self.bn4 = nn.BatchNorm1d(512)\n",
    "        self.bn5 = nn.BatchNorm1d(256)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        batchsize = x.size()[0]\n",
    "        # shared MLP\n",
    "        x = F.relu((self.conv1(x)))\n",
    "        x = F.relu((self.conv2(x)))\n",
    "        x = F.relu((self.conv3(x)))\n",
    "        # max pool\n",
    "        x = torch.max(x, 2, keepdim=True)[0]\n",
    "        x = x.view(-1, 1024)\n",
    "        # FC layers\n",
    "        x = F.relu((self.fc1(x)))\n",
    "        x = F.relu((self.fc2(x)))\n",
    "        # output layer\n",
    "        x = self.fc3(x)\n",
    "        # 3x3 output matrix\n",
    "        iden = torch.eye(3, dtype=x.dtype, device=x.device).view(1,9).repeat(batchsize, 1)\n",
    "        x = x + iden\n",
    "        x = x.view(-1,3,3)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3h2VrkBQmVMK"
   },
   "source": [
    "## Feature Transform Layer\n",
    "\n",
    "This layer corresponds to the input transform layer as described in PointNet architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uayji2-mmd7S"
   },
   "outputs": [],
   "source": [
    "class TNet64(nn.Module):\n",
    "    '''\n",
    "    T-Net implementation with 3x3 transform as output\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        super(TNet64,self).__init__()\n",
    "        # shared MLP\n",
    "        self.conv1 = nn.Conv1d(64,64,1)\n",
    "        self.conv2 = nn.Conv1d(64,128,1)\n",
    "        self.conv3 = nn.Conv1d(128,1024,1)\n",
    "        # fc layers\n",
    "        self.fc1 = nn.Linear(1024,512)\n",
    "        self.fc2 = nn.Linear(512,256)\n",
    "        # output layer\n",
    "        self.fc3 = nn.Linear(256,64*64)\n",
    "        # batch norm layers\n",
    "        self.bn1 = nn.BatchNorm1d(64)\n",
    "        self.bn2 = nn.BatchNorm1d(128)\n",
    "        self.bn3 = nn.BatchNorm1d(1024)\n",
    "        self.bn4 = nn.BatchNorm1d(512)\n",
    "        self.bn5 = nn.BatchNorm1d(256)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        batchsize = x.size()[0]\n",
    "        # shared MLP\n",
    "        x = F.relu((self.conv1(x)))\n",
    "        x = F.relu((self.conv2(x)))\n",
    "        x = F.relu((self.conv3(x)))\n",
    "        # max pool\n",
    "        x = torch.max(x, 2, keepdim=True)[0]\n",
    "        x = x.view(-1, 1024)\n",
    "        # FC layers\n",
    "        x = F.relu((self.fc1(x)))\n",
    "        x = F.relu((self.fc2(x)))\n",
    "        # output layer\n",
    "        x = self.fc3(x)\n",
    "        # 3x3 output matrix\n",
    "        iden = torch.eye(64, dtype=x.dtype, device=x.device).view(1,64*64).repeat(batchsize, 1)\n",
    "        x = x + iden\n",
    "        x = x.view(-1,64,64)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bJFXXjIFnU-x"
   },
   "source": [
    "## PointNet Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RNAIqWyP4gwl"
   },
   "source": [
    "Implements PointNet architecture for extracting global features. The commented lines show the parts of PointNet that have been modified in OBBNet for better results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "id": "LQvNGZH8nYvD"
   },
   "outputs": [],
   "source": [
    "class PointNet(nn.Module):\n",
    "    '''\n",
    "    1024 dimensional feature as output\n",
    "    '''\n",
    "    def __init__(self,has_input_tf=True,has_feature_tf=True):\n",
    "        super(PointNet,self).__init__()\n",
    "        # flags to control the transformation layers\n",
    "        self.has_input_tf = has_input_tf\n",
    "        self.has_feature_tf = has_feature_tf\n",
    "        # input transform\n",
    "        self.tnet3 = TNet3()\n",
    "        # feature transform\n",
    "        self.tnet64 = TNet64()\n",
    "\n",
    "        # shared MLP(64,128,1024)\n",
    "        self.conv21 = nn.Conv1d(3,64,1)\n",
    "        self.conv22 = nn.Conv1d(64,128,1)\n",
    "        self.conv23 = nn.Conv1d(128,1024,1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        '''\n",
    "        input will be of the form (batch_size,3,n)\n",
    "        '''\n",
    "        # input transform\n",
    "        if self.has_input_tf:\n",
    "            input_tf = self.tnet3(x)\n",
    "            # matrix multiply\n",
    "            x = x.transpose(2,1) # shape: (batch_size,n,3)\n",
    "            x = torch.bmm(x, input_tf) # shape: (batch_size,n,3)\n",
    "            x = x.transpose(2,1) # shape: (batch_size,3,n)\n",
    "\n",
    "\n",
    "        # feature transform\n",
    "        if self.has_feature_tf:\n",
    "            feature_tf = self.tnet64(x)\n",
    "            # matrix multiply\n",
    "            x = x.transpose(2,1) # shape: (batch_size,n,64)\n",
    "            x = torch.bmm(x, feature_tf) # shape: (batch_size,n,64)\n",
    "            x = x.transpose(2,1) # shape: (batch_size,64,n)\n",
    "        \n",
    "        # shared MLP(64,128,1024)\n",
    "        x = F.relu((self.conv21(x)))\n",
    "        x = F.relu((self.conv22(x)))\n",
    "        x = (self.conv23(x))\n",
    "        \n",
    "        # maxpool\n",
    "        x = torch.max(x, 2, keepdim=True)[0]\n",
    "        \n",
    "        # global feature\n",
    "        x = x.view(-1,1024)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FZ2IkaPgnpac"
   },
   "source": [
    "## OBB Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i5mQeeLXrDVU"
   },
   "source": [
    "Extension of PointNet to extract bounding box parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "id": "gliZ5rbjnv6h"
   },
   "outputs": [],
   "source": [
    "class OBBNet(nn.Module):\n",
    "    '''\n",
    "    Outputs OBB\n",
    "    '''\n",
    "    def __init__(self,has_input_tf, has_feature_tf):\n",
    "        super(OBBNet, self).__init__()\n",
    "        self.has_input_tf = has_input_tf\n",
    "        self.has_feature_tf = has_feature_tf\n",
    "        \n",
    "        # PointNet global features\n",
    "        self.pt_fts = PointNet(self.has_input_tf, self.has_feature_tf)\n",
    "        \n",
    "        # fc layers\n",
    "        self.fc1 = nn.Linear(1024,512)\n",
    "        self.fc2 = nn.Linear(512,256)\n",
    "        self.fc3 = nn.Linear(256,6)\n",
    "        self.fc4 = nn.Linear(1024,512)\n",
    "        self.fc5 = nn.Linear(512,256)\n",
    "        self.fc6 = nn.Linear(256,4)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.pt_fts(x)\n",
    "        # regress center and extent\n",
    "        x1 = F.relu(self.fc1(x))\n",
    "        x1 = F.relu(self.fc2(x1))\n",
    "        x1 = (self.fc3(x1))\n",
    "        # regress orientation\n",
    "        x2 = F.relu(self.fc4(x))\n",
    "        x2 = F.relu(self.fc5(x2))\n",
    "        x2 = (self.fc6(x2))\n",
    "\n",
    "        return x1,x2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x1yh4fNr_0xZ"
   },
   "source": [
    "# Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "id": "pFqFS5fpU9AC"
   },
   "outputs": [],
   "source": [
    "# custom Dataset class\n",
    "class OBBDataset(Dataset):\n",
    "    def __init__(self,jsonfilename,rootdir):\n",
    "        '''\n",
    "        jsonfilename : filename of the json file containing \n",
    "                       ground truth labels\n",
    "        rootdir : root directory of the dataset\n",
    "        '''\n",
    "        with open(jsonfilename) as fp:\n",
    "            self.obb_json = json.load(fp)\n",
    "        self.filenames = list(self.obb_json.keys())\n",
    "        self.rootdir = rootdir\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.filenames)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        \n",
    "        # load the corresponding point cloud\n",
    "        filename = self.filenames[idx]\n",
    "        filepath = os.path.join(self.rootdir,filename)\n",
    "        pcd = o3d.io.read_point_cloud(filepath)\n",
    "        pcd_points = np.asarray(pcd.points).astype(np.float32)\n",
    "\n",
    "        # get obb\n",
    "        # obb = self.obb_json[filename]\n",
    "        obb = pcd.get_oriented_bounding_box()\n",
    "        obb_center = np.array(obb.center, dtype=np.float32)\n",
    "        obb_extent = np.array(obb.extent, dtype=np.float32)\n",
    "        obb_r = np.array(obb.R, dtype = np.float32)#.reshape(3,3)\n",
    "        \n",
    "        # # convert to quarternions\n",
    "        obb_center = torch.tensor(obb_center)\n",
    "        obb_extent = torch.tensor(obb_extent)\n",
    "        obb_r = torch.tensor(obb_r)\n",
    "        obb_q = matrix_to_quaternion(obb_r)\n",
    "        obb_params = torch.cat((obb_center, obb_extent, obb_q))\n",
    "        # obb_params = torch.cat((obb_center, obb_extent, obb_r))\n",
    "\n",
    "        return pcd_points, obb_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DiZYtm9VrP32"
   },
   "source": [
    "Load training and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "id": "45FBEslYH9sy"
   },
   "outputs": [],
   "source": [
    "train_labels = '/content/drive/MyDrive/COMP0119/Datasets/shapenet_train_labels.json'\n",
    "test_labels = '/content/drive/MyDrive/COMP0119/Datasets/shapenet_test_labels.json'\n",
    "rootdir = '/content/drive/MyDrive/COMP0119/Datasets/shapenet5k'\n",
    "\n",
    "train_set = OBBDataset(jsonfilename=train_labels,\n",
    "                       rootdir=rootdir)\n",
    "test_set = OBBDataset(jsonfilename=test_labels,\n",
    "                      rootdir=rootdir)\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "train_loader = DataLoader(train_set,batch_size=batch_size)\n",
    "test_loader = DataLoader(test_set,batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-JrIkK2KQaRU"
   },
   "source": [
    "# Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "id": "Fn0G7mw4qcaG"
   },
   "outputs": [],
   "source": [
    "# get GPU if possible\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "id": "WzEUJJLGQdBT"
   },
   "outputs": [],
   "source": [
    "# define network object\n",
    "net = OBBNet(has_input_tf = False, has_feature_tf = False)\n",
    "net.to(device)\n",
    "# MSE loss\n",
    "criterion = nn.MSELoss(reduction='sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "id": "0aXwXIPJpY10"
   },
   "outputs": [],
   "source": [
    "# optimizer \n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "id": "hij1qs1Ycl5N"
   },
   "outputs": [],
   "source": [
    "def qloss(t1,t2):\n",
    "    '''\n",
    "    computes the geodesic distance between a quarternion pair\n",
    "    '''\n",
    "    t = torch.mul(t1,t2).sum(dim=1)**2\n",
    "    t = 1-t\n",
    "    return t.norm()**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "id": "WHt2ZLwo7W4C"
   },
   "outputs": [],
   "source": [
    "blue = lambda x: '\\033[94m' + x + '\\033[0m'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 100\n",
    "lossRecord = []\n",
    "for epoch in range(num_epochs):\n",
    "    # print('Epoch: ',epoch)\n",
    "    net.train()\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs,labels = data\n",
    "        inputs,labels = inputs.to(device),labels.to(device)\n",
    "        inputs = inputs.transpose(2,1)\n",
    "        optimizer.zero_grad()\n",
    "        output1,output2 = net(inputs)\n",
    "        # loss_1 = criterion(outputs[:,:3],labels[:,:3])\n",
    "        # loss_2 = criterion(outputs[:,3:6],labels[:,3:6])\n",
    "        # loss_3 = qloss(outputs[:,6:],labels[:,6:])\n",
    "        # penalty = (outputs[:,6:].norm(dim=1)**2 - 1)**2\n",
    "        # loss = loss_1 + 5*loss_2 + loss_3 + 10*penalty.sum() \n",
    "        d_loss = criterion(output1,labels[:,:6])\n",
    "        penalty = (output2.norm(dim=1)**2 - 1)**2\n",
    "        q_loss = qloss(output2,labels[:,6:]) + 10*penalty.sum()\n",
    "        loss = 10*d_loss + q_loss \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    lossRecord.append(running_loss / len(train_loader))\n",
    "    # print training metrics\n",
    "    print('Epoch: %d | Loss: %.5f' %\n",
    "            (epoch + 1, running_loss / len(train_loader)))\n",
    "    \n",
    "    # test performance on test set every 10 epochs\n",
    "    if ((epoch+1)%10==0):\n",
    "        net.eval()\n",
    "        test_itr = iter(test_loader)\n",
    "        inputs,labels = next(test_itr)\n",
    "        inputs,labels = inputs.to(device),labels.to(device)\n",
    "        inputs = inputs.transpose(2,1)\n",
    "        output1,output2 = net(inputs)\n",
    "        # loss_1 = criterion(outputs[:,:3],labels[:,:3])\n",
    "        # loss_2 = criterion(outputs[:,3:6],labels[:,3:6])\n",
    "        # loss_3 = qloss(outputs[:,6:],labels[:,6:])\n",
    "        # train_loss = (loss_1 + loss_2 + loss_3).item()\n",
    "        d_loss = criterion(output1,labels[:,:6])\n",
    "        q_loss = qloss(output2,labels[:,6:]) \n",
    "        train_loss = 10*d_loss + q_loss\n",
    "        print('%s Loss: %.5f' %\n",
    "            (blue('Test'),train_loss))\n",
    "    # writer.add_scalar('Loss/train',running_loss / len(train_loader), epoch)\n",
    "    scheduler.step()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(lossRecord)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZSNWJqW5rbrf"
   },
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "htbFZym3GO7m"
   },
   "outputs": [],
   "source": [
    "torch.save(net.to(torch.device('cpu')).state_dict(),'net_5k.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-PEZKiV-DjJ8"
   },
   "outputs": [],
   "source": [
    "with open(test_labels,'r') as fp:\n",
    "    obb_dict = json.load(fp)\n",
    "\n",
    "filenames = list(obb_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BpcNz12-_kpk"
   },
   "outputs": [],
   "source": [
    "# on test set\n",
    "net.to(torch.device('cpu'))\n",
    "criterion = nn.MSELoss()\n",
    "test_loader = DataLoader(test_set,batch_size=1)\n",
    "\n",
    "net.eval()\n",
    "i = 0\n",
    "\n",
    "test_res = {}\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        inputs, labels = data\n",
    "        inputs,labels = inputs,labels\n",
    "        inputs = inputs.transpose(2,1)\n",
    "        output1,output2 = net(inputs)\n",
    "        \n",
    "        d_loss = criterion(output1,labels[:,:6])\n",
    "        q_loss = qloss(output2,labels[:,6:]) \n",
    "        loss = d_loss + q_loss\n",
    "        loss = loss.item()\n",
    "\n",
    "        obb_center = output1[:,:3].flatten().tolist()\n",
    "        obb_extent = output1[:,3:6].flatten().tolist()\n",
    "        obb_r = quaternion_to_matrix(output2)\n",
    "        obb_r = obb_r.view(3,3).tolist()\n",
    "\n",
    "        # save output into dictionary\n",
    "        test_res[filenames[i]] = {\n",
    "        'center':obb_center,\n",
    "        'extent':obb_extent,\n",
    "        'R':obb_r\n",
    "        }\n",
    "\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XfFhV97oDqOp"
   },
   "outputs": [],
   "source": [
    "# save results into a json file\n",
    "with open('res_shapenet.json','w') as fp:\n",
    "    json.dump(test_res,fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f0rq2MAnHBPk"
   },
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "jB95HytCsIjh"
   },
   "outputs": [],
   "source": [
    "with open('res_shapenet.json','r') as fp:\n",
    "    test_res = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "fNHGJkaMtLvS"
   },
   "outputs": [],
   "source": [
    "def evaluate(filename,data_root,disp=False):\n",
    "    filepath = os.path.join(data_root,filename)\n",
    "    pcd = o3d.io.read_point_cloud(filepath)\n",
    "    # axis aligned bb\n",
    "    aabb = pcd.get_axis_aligned_bounding_box()\n",
    "    aabb_line_set = o3d.geometry.LineSet.create_from_axis_aligned_bounding_box(aabb)\n",
    "    aabb_line_set.paint_uniform_color([1,0,0])\n",
    "    # true obb\n",
    "    obb = obb_dict[filename]\n",
    "    obb_center = np.array(obb['center'], dtype=np.float32).reshape(3,1)\n",
    "    obb_extent = np.array(obb['extent'], dtype=np.float32).reshape(3,1)\n",
    "    obb_r = np.array(obb['R'], dtype = np.float32).reshape(3,3)\n",
    "    obb = o3d.geometry.OrientedBoundingBox(center=obb_center, extent=obb_extent, R=obb_r)\n",
    "    obb_line_set = o3d.geometry.LineSet.create_from_oriented_bounding_box(obb)\n",
    "    obb_line_set.paint_uniform_color([1,0,0])\n",
    "    # predicted obb\n",
    "    pred_obb = test_res[filename]\n",
    "    pred_obb_center = np.array(pred_obb['center'], dtype=np.float32).reshape(3,1)\n",
    "    pred_obb_extent = np.array(pred_obb['extent'], dtype=np.float32).reshape(3,1)\n",
    "    pred_obb_r = np.array(pred_obb['R'], dtype = np.float32).reshape(3,3)\n",
    "    pred_obb = o3d.geometry.OrientedBoundingBox(\n",
    "        center=pred_obb_center,\n",
    "        extent=pred_obb_extent+0.05, \n",
    "        R=pred_obb_r)\n",
    "    pred_obb_line_set = o3d.geometry.LineSet.create_from_oriented_bounding_box(pred_obb)\n",
    "    pred_obb_line_set.paint_uniform_color([0,0,1])\n",
    "    if disp:\n",
    "        o3d.visualization.draw_geometries([pcd,pred_obb_line_set,obb_line_set])\n",
    "    # \n",
    "    print(obb_r)\n",
    "    print(pred_obb_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "5JLdeHpitNpd"
   },
   "outputs": [],
   "source": [
    "test_filenames = list(test_res.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MDC2KzLotQvj"
   },
   "outputs": [],
   "source": [
    "idx = 41\n",
    "filename = test_filenames[idx]\n",
    "print(filename)\n",
    "evaluate(filename,rootdir,disp=1)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": " COMP0119_CW3_v2.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
